[net]
batch=64
subdivisions=8
height=1024
width=1024
channels=3
learning_rate=0.0001
momentum=0.9
decay=0.0005
seen=0

max_batches = 30000
burn_in=1000
policy=steps
steps=2500,5000,14000,18000,20000
scales=.5,.1,.1,.1,.1

#1 1024 3->16
[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

#2 512 16->32
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

#3 256 32->64
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

#4 128 64->128
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

#5 64 128->256
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

#6 32 256->512
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=1

#7 32 512->1024
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky
stopbackward=1

##########
#8 32 1024->256
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

#9 32 256->512
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#10 32x32 512->1
[convolutional]
batch_normalize=1
filters=1
size=1
stride=1
pad=1
activation=logistic

[cost]

